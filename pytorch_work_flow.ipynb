{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa42bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31234bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000],\n",
       "        [0.3140],\n",
       "        [0.3280],\n",
       "        [0.3420],\n",
       "        [0.3560],\n",
       "        [0.3700],\n",
       "        [0.3840],\n",
       "        [0.3980],\n",
       "        [0.4120],\n",
       "        [0.4260]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Data Preparation and Loading\n",
    "# create **known** parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# create \n",
    "start = 0\n",
    "end = 1\n",
    "steps = 0.02\n",
    "X = torch.arange(start, end, steps).unsqueeze(dim=1) # add 1 dims\n",
    "\n",
    "y = weight * X + bias\n",
    "X[:10]\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0604ece6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc674f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Spliting data into training and test sets    \n",
    "# traing, validation and test set\n",
    "\n",
    "# creating training set\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94397e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a# Visualize, Visualize, Visualize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf38444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14})\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b5dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f889bcf",
   "metadata": {},
   "source": [
    "#### Build a model\n",
    "Create linear regression model class\n",
    " building classes that can use the following link:\n",
    "https://realpython.com/python-classes/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663a2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what model does:\n",
    "# start with random weights and bias\n",
    "# look at the training data and adjust weights and bias to better represent the data\n",
    "\n",
    "# through two main algorithms:\n",
    "# 1. Gradient Descent\n",
    "# 2. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65540223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # initialize model parameters (weights and bias)\n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                                requires_grad = True,\n",
    "                                                dtype = torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad = True,\n",
    "                                             dtype = torch.float))\n",
    "        # Forward method to define the computation in the model\n",
    "    def forward(self,x: torch.Tensor) -> torch.Tensor: # x is input data\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8be721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through two main algorithms\n",
    "# 1. Gradient descent\n",
    "# 2. Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9222c0c",
   "metadata": {},
   "source": [
    "### Pytorch model biulding essential \n",
    "\n",
    "__torch.nn__ - contains all of the buildings for computational graphs\n",
    "\n",
    "__torch.nn.Parameter__ - what parameters should our model try and learn\n",
    "\n",
    "__torch.nn.Module__ - The base class for all neural network modules\n",
    "\n",
    "__torch.optim__ - this where the optimizers in PyTorch live, help with gradient descent\n",
    "\n",
    "__def forward()__ - All nn.Module subclasses require you to overwrite forward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d6e2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([1.0908])), ('bias', tensor([0.7446]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "## access to the model parameters\n",
    "model_0.parameters()\n",
    "\n",
    "torch.manual_seed(42)   # reproducibility of the model parameters\n",
    "\n",
    "list(model_0.parameters())\n",
    "\n",
    "## the better way to access model parameters\n",
    "model_0.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60261897",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ideal parameters are predefined earlier\n",
    "# weight = 0.7\n",
    "# bias = 0.3\n",
    "\n",
    "# the model task is to start from random parameters and learn the ideal parameters\n",
    "# making prediction using `torch.inference_mode()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7887106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8000],\n",
       "         [0.8200],\n",
       "         [0.8400],\n",
       "         [0.8600],\n",
       "         [0.8800],\n",
       "         [0.9000],\n",
       "         [0.9200],\n",
       "         [0.9400],\n",
       "         [0.9600],\n",
       "         [0.9800]]),\n",
       " tensor([[0.8600],\n",
       "         [0.8740],\n",
       "         [0.8880],\n",
       "         [0.9020],\n",
       "         [0.9160],\n",
       "         [0.9300],\n",
       "         [0.9440],\n",
       "         [0.9580],\n",
       "         [0.9720],\n",
       "         [0.9860]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a855f805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6173],\n",
       "        [1.6391],\n",
       "        [1.6609],\n",
       "        [1.6828],\n",
       "        [1.7046],\n",
       "        [1.7264],\n",
       "        [1.7482],\n",
       "        [1.7700],\n",
       "        [1.7918],\n",
       "        [1.8137]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how model predicts `y_test` based on `X_test`\n",
    "with torch.inference_mode():   # this disables gradient tracking, make pytorch use less memory\n",
    "    y_preds = model_0(X_test)\n",
    "y_preds\n",
    "\n",
    "## alternatively one can use\n",
    "# with torch.no_grad():\n",
    "#     y_preds = model_0(X_test)\n",
    "# y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31b451ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## lets compare predictions with ideal values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.scatter(X_train, y_train, label=\"Training Values\")\n",
    "plt.scatter(X_test, y_test, label=\"Ideal Values\", c = 'g')\n",
    "plt.scatter(X_test, y_preds, label=\"Model Predictions\", c = 'r')\n",
    "plt.legend()\n",
    "plt.show()    # poor model! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe4f54",
   "metadata": {},
   "source": [
    "### Train model\n",
    "training model to move from some __unknown__ parms to some __known__ parms. \n",
    "\n",
    "one way: use __loss function__ \n",
    "\n",
    "* **Loss Function** A func to measure how wrong your models pred to ideal outputs, lower is better\n",
    "\n",
    "* __Optimizer__: takes into account the loss and adjust model's parms to improve the loss func, where we need\n",
    "    * A training loop\n",
    "    * A testing loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624bbf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "349aa843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1.0908], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.7446], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## kind of loss functions\n",
    "## 1. Mean Absolute Error Loss --> `torch.nn.L1Loss()`          -- l_n = |y - ŷ|\n",
    "## 2. Mean Squared Error Loss --> `torch.nn.MSELoss()`          -- l_n = (y - ŷ)²\n",
    "## 3. Cross Entropy Loss --> `torch.nn.CrossEntropyLoss()`      -- l_n = -Σ(y * log(ŷ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66bfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924e7e5c",
   "metadata": {},
   "source": [
    "## Building a training loop in PyTorch\n",
    "\n",
    "0. loop through the data\n",
    "1. Forward pass  to make preds on data\n",
    "2. Calculate the loss\n",
    "3. Optomizer zero grad\n",
    "4. Loss Backward \n",
    "5. Optimizer step (__gradiant descent__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "553f987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use MAE loss\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "## setup an optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD(params = model_0.parameters(), lr=0.01)   # lr = learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b20364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5970739722251892\n",
      "OrderedDict({'weights': tensor([1.0869]), 'bias': tensor([0.7346])})\n",
      "Loss: 0.585552990436554\n",
      "OrderedDict({'weights': tensor([1.0830]), 'bias': tensor([0.7246])})\n",
      "Loss: 0.5740319490432739\n",
      "OrderedDict({'weights': tensor([1.0791]), 'bias': tensor([0.7146])})\n",
      "Loss: 0.5625109672546387\n",
      "OrderedDict({'weights': tensor([1.0752]), 'bias': tensor([0.7046])})\n",
      "Loss: 0.5509899258613586\n",
      "OrderedDict({'weights': tensor([1.0713]), 'bias': tensor([0.6946])})\n",
      "Loss: 0.5394688844680786\n",
      "OrderedDict({'weights': tensor([1.0674]), 'bias': tensor([0.6846])})\n",
      "Loss: 0.5279479622840881\n",
      "OrderedDict({'weights': tensor([1.0635]), 'bias': tensor([0.6746])})\n",
      "Loss: 0.5164269208908081\n",
      "OrderedDict({'weights': tensor([1.0596]), 'bias': tensor([0.6646])})\n",
      "Loss: 0.5049058794975281\n",
      "OrderedDict({'weights': tensor([1.0557]), 'bias': tensor([0.6546])})\n",
      "Loss: 0.4933848977088928\n",
      "OrderedDict({'weights': tensor([1.0518]), 'bias': tensor([0.6446])})\n",
      "Loss: 0.4818638861179352\n",
      "OrderedDict({'weights': tensor([1.0479]), 'bias': tensor([0.6346])})\n",
      "Loss: 0.4703429341316223\n",
      "OrderedDict({'weights': tensor([1.0440]), 'bias': tensor([0.6246])})\n",
      "Loss: 0.4588218629360199\n",
      "OrderedDict({'weights': tensor([1.0401]), 'bias': tensor([0.6146])})\n",
      "Loss: 0.44730085134506226\n",
      "OrderedDict({'weights': tensor([1.0362]), 'bias': tensor([0.6046])})\n",
      "Loss: 0.43577975034713745\n",
      "OrderedDict({'weights': tensor([1.0323]), 'bias': tensor([0.5946])})\n",
      "Loss: 0.42425885796546936\n",
      "OrderedDict({'weights': tensor([1.0284]), 'bias': tensor([0.5846])})\n",
      "Loss: 0.41273778676986694\n",
      "OrderedDict({'weights': tensor([1.0245]), 'bias': tensor([0.5746])})\n",
      "Loss: 0.4012168347835541\n",
      "OrderedDict({'weights': tensor([1.0206]), 'bias': tensor([0.5646])})\n",
      "Loss: 0.38969579339027405\n",
      "OrderedDict({'weights': tensor([1.0167]), 'bias': tensor([0.5546])})\n",
      "Loss: 0.3781747817993164\n",
      "OrderedDict({'weights': tensor([1.0128]), 'bias': tensor([0.5446])})\n",
      "Loss: 0.36665377020835876\n",
      "OrderedDict({'weights': tensor([1.0089]), 'bias': tensor([0.5346])})\n",
      "Loss: 0.3551327586174011\n",
      "OrderedDict({'weights': tensor([1.0050]), 'bias': tensor([0.5246])})\n",
      "Loss: 0.3436117470264435\n",
      "OrderedDict({'weights': tensor([1.0011]), 'bias': tensor([0.5146])})\n",
      "Loss: 0.3320907652378082\n",
      "OrderedDict({'weights': tensor([0.9972]), 'bias': tensor([0.5046])})\n",
      "Loss: 0.3205697536468506\n",
      "OrderedDict({'weights': tensor([0.9933]), 'bias': tensor([0.4946])})\n",
      "Loss: 0.30904877185821533\n",
      "OrderedDict({'weights': tensor([0.9894]), 'bias': tensor([0.4846])})\n",
      "Loss: 0.2975277900695801\n",
      "OrderedDict({'weights': tensor([0.9855]), 'bias': tensor([0.4746])})\n",
      "Loss: 0.2860068082809448\n",
      "OrderedDict({'weights': tensor([0.9816]), 'bias': tensor([0.4646])})\n",
      "Loss: 0.27448582649230957\n",
      "OrderedDict({'weights': tensor([0.9777]), 'bias': tensor([0.4546])})\n",
      "Loss: 0.26296481490135193\n",
      "OrderedDict({'weights': tensor([0.9738]), 'bias': tensor([0.4446])})\n",
      "Loss: 0.2514438331127167\n",
      "OrderedDict({'weights': tensor([0.9699]), 'bias': tensor([0.4346])})\n",
      "Loss: 0.23992285132408142\n",
      "OrderedDict({'weights': tensor([0.9660]), 'bias': tensor([0.4246])})\n",
      "Loss: 0.22840186953544617\n",
      "OrderedDict({'weights': tensor([0.9621]), 'bias': tensor([0.4146])})\n",
      "Loss: 0.21688087284564972\n",
      "OrderedDict({'weights': tensor([0.9582]), 'bias': tensor([0.4046])})\n",
      "Loss: 0.20535989105701447\n",
      "OrderedDict({'weights': tensor([0.9543]), 'bias': tensor([0.3946])})\n",
      "Loss: 0.1938389092683792\n",
      "OrderedDict({'weights': tensor([0.9504]), 'bias': tensor([0.3846])})\n",
      "Loss: 0.18231791257858276\n",
      "OrderedDict({'weights': tensor([0.9465]), 'bias': tensor([0.3746])})\n",
      "Loss: 0.1707969307899475\n",
      "OrderedDict({'weights': tensor([0.9426]), 'bias': tensor([0.3646])})\n",
      "Loss: 0.15927593410015106\n",
      "OrderedDict({'weights': tensor([0.9387]), 'bias': tensor([0.3546])})\n",
      "Loss: 0.1477549523115158\n",
      "OrderedDict({'weights': tensor([0.9348]), 'bias': tensor([0.3446])})\n",
      "Loss: 0.13623395562171936\n",
      "OrderedDict({'weights': tensor([0.9309]), 'bias': tensor([0.3346])})\n",
      "Loss: 0.1247129812836647\n",
      "OrderedDict({'weights': tensor([0.9270]), 'bias': tensor([0.3246])})\n",
      "Loss: 0.11319198459386826\n",
      "OrderedDict({'weights': tensor([0.9231]), 'bias': tensor([0.3146])})\n",
      "Loss: 0.101671002805233\n",
      "OrderedDict({'weights': tensor([0.9192]), 'bias': tensor([0.3046])})\n",
      "Loss: 0.09015001356601715\n",
      "OrderedDict({'weights': tensor([0.9153]), 'bias': tensor([0.2946])})\n",
      "Loss: 0.0789487287402153\n",
      "OrderedDict({'weights': tensor([0.9114]), 'bias': tensor([0.2856])})\n",
      "Loss: 0.06971335411071777\n",
      "OrderedDict({'weights': tensor([0.9076]), 'bias': tensor([0.2776])})\n",
      "Loss: 0.06220541521906853\n",
      "OrderedDict({'weights': tensor([0.9039]), 'bias': tensor([0.2706])})\n",
      "Loss: 0.05618410184979439\n",
      "OrderedDict({'weights': tensor([0.9002]), 'bias': tensor([0.2646])})\n",
      "Loss: 0.0514393225312233\n",
      "OrderedDict({'weights': tensor([0.8967]), 'bias': tensor([0.2591])})\n",
      "Loss: 0.04750905930995941\n",
      "OrderedDict({'weights': tensor([0.8933]), 'bias': tensor([0.2546])})\n",
      "Loss: 0.04450256749987602\n",
      "OrderedDict({'weights': tensor([0.8901]), 'bias': tensor([0.2506])})\n",
      "Loss: 0.04203909635543823\n",
      "OrderedDict({'weights': tensor([0.8870]), 'bias': tensor([0.2471])})\n",
      "Loss: 0.04007718712091446\n",
      "OrderedDict({'weights': tensor([0.8841]), 'bias': tensor([0.2446])})\n",
      "Loss: 0.03864547610282898\n",
      "OrderedDict({'weights': tensor([0.8814]), 'bias': tensor([0.2426])})\n",
      "Loss: 0.03751649707555771\n",
      "OrderedDict({'weights': tensor([0.8787]), 'bias': tensor([0.2406])})\n",
      "Loss: 0.03649530187249184\n",
      "OrderedDict({'weights': tensor([0.8762]), 'bias': tensor([0.2391])})\n",
      "Loss: 0.03567240387201309\n",
      "OrderedDict({'weights': tensor([0.8738]), 'bias': tensor([0.2381])})\n",
      "Loss: 0.03501071408390999\n",
      "OrderedDict({'weights': tensor([0.8715]), 'bias': tensor([0.2371])})\n",
      "Loss: 0.034405406564474106\n",
      "OrderedDict({'weights': tensor([0.8693]), 'bias': tensor([0.2366])})\n",
      "Loss: 0.033900801092386246\n",
      "OrderedDict({'weights': tensor([0.8671]), 'bias': tensor([0.2361])})\n",
      "Loss: 0.03341434523463249\n",
      "OrderedDict({'weights': tensor([0.8651]), 'bias': tensor([0.2361])})\n",
      "Loss: 0.03301435336470604\n",
      "OrderedDict({'weights': tensor([0.8631]), 'bias': tensor([0.2361])})\n",
      "Loss: 0.03261435776948929\n",
      "OrderedDict({'weights': tensor([0.8611]), 'bias': tensor([0.2361])})\n",
      "Loss: 0.03221435844898224\n",
      "OrderedDict({'weights': tensor([0.8591]), 'bias': tensor([0.2361])})\n",
      "Loss: 0.03182544559240341\n",
      "OrderedDict({'weights': tensor([0.8573]), 'bias': tensor([0.2366])})\n",
      "Loss: 0.031476445496082306\n",
      "OrderedDict({'weights': tensor([0.8555]), 'bias': tensor([0.2371])})\n",
      "Loss: 0.0311274491250515\n",
      "OrderedDict({'weights': tensor([0.8537]), 'bias': tensor([0.2376])})\n",
      "Loss: 0.03077845275402069\n",
      "OrderedDict({'weights': tensor([0.8519]), 'bias': tensor([0.2381])})\n",
      "Loss: 0.030429448932409286\n",
      "OrderedDict({'weights': tensor([0.8501]), 'bias': tensor([0.2386])})\n",
      "Loss: 0.03008044883608818\n",
      "OrderedDict({'weights': tensor([0.8483]), 'bias': tensor([0.2391])})\n",
      "Loss: 0.029731452465057373\n",
      "OrderedDict({'weights': tensor([0.8465]), 'bias': tensor([0.2396])})\n",
      "Loss: 0.02938244864344597\n",
      "OrderedDict({'weights': tensor([0.8447]), 'bias': tensor([0.2401])})\n",
      "Loss: 0.029033448547124863\n",
      "OrderedDict({'weights': tensor([0.8429]), 'bias': tensor([0.2406])})\n",
      "Loss: 0.028684448450803757\n",
      "OrderedDict({'weights': tensor([0.8411]), 'bias': tensor([0.2411])})\n",
      "Loss: 0.02833545207977295\n",
      "OrderedDict({'weights': tensor([0.8393]), 'bias': tensor([0.2416])})\n",
      "Loss: 0.027986448258161545\n",
      "OrderedDict({'weights': tensor([0.8375]), 'bias': tensor([0.2421])})\n",
      "Loss: 0.02764306031167507\n",
      "OrderedDict({'weights': tensor([0.8359]), 'bias': tensor([0.2431])})\n",
      "Loss: 0.0273012463003397\n",
      "OrderedDict({'weights': tensor([0.8341]), 'bias': tensor([0.2436])})\n",
      "Loss: 0.026954054832458496\n",
      "OrderedDict({'weights': tensor([0.8325]), 'bias': tensor([0.2446])})\n",
      "Loss: 0.026616042479872704\n",
      "OrderedDict({'weights': tensor([0.8307]), 'bias': tensor([0.2451])})\n",
      "Loss: 0.026267046108841896\n",
      "OrderedDict({'weights': tensor([0.8289]), 'bias': tensor([0.2456])})\n",
      "Loss: 0.025928836315870285\n",
      "OrderedDict({'weights': tensor([0.8273]), 'bias': tensor([0.2466])})\n",
      "Loss: 0.0255818422883749\n",
      "OrderedDict({'weights': tensor([0.8255]), 'bias': tensor([0.2471])})\n",
      "Loss: 0.02523983083665371\n",
      "OrderedDict({'weights': tensor([0.8239]), 'bias': tensor([0.2481])})\n",
      "Loss: 0.024896642193198204\n",
      "OrderedDict({'weights': tensor([0.8221]), 'bias': tensor([0.2486])})\n",
      "Loss: 0.02455081418156624\n",
      "OrderedDict({'weights': tensor([0.8205]), 'bias': tensor([0.2496])})\n",
      "Loss: 0.024211443960666656\n",
      "OrderedDict({'weights': tensor([0.8187]), 'bias': tensor([0.2501])})\n",
      "Loss: 0.023862436413764954\n",
      "OrderedDict({'weights': tensor([0.8169]), 'bias': tensor([0.2506])})\n",
      "Loss: 0.023525599390268326\n",
      "OrderedDict({'weights': tensor([0.8153]), 'bias': tensor([0.2516])})\n",
      "Loss: 0.023177240043878555\n",
      "OrderedDict({'weights': tensor([0.8135]), 'bias': tensor([0.2521])})\n",
      "Loss: 0.0228365920484066\n",
      "OrderedDict({'weights': tensor([0.8119]), 'bias': tensor([0.2531])})\n",
      "Loss: 0.02249203622341156\n",
      "OrderedDict({'weights': tensor([0.8101]), 'bias': tensor([0.2536])})\n",
      "Loss: 0.02214757725596428\n",
      "OrderedDict({'weights': tensor([0.8086]), 'bias': tensor([0.2546])})\n",
      "Loss: 0.021806836128234863\n",
      "OrderedDict({'weights': tensor([0.8068]), 'bias': tensor([0.2551])})\n",
      "Loss: 0.021458571776747704\n",
      "OrderedDict({'weights': tensor([0.8052]), 'bias': tensor([0.2561])})\n",
      "Loss: 0.02112163044512272\n",
      "OrderedDict({'weights': tensor([0.8034]), 'bias': tensor([0.2566])})\n",
      "Loss: 0.020772628486156464\n",
      "OrderedDict({'weights': tensor([0.8016]), 'bias': tensor([0.2571])})\n",
      "Loss: 0.02043335698544979\n",
      "OrderedDict({'weights': tensor([0.8000]), 'bias': tensor([0.2581])})\n",
      "Loss: 0.020087428390979767\n",
      "OrderedDict({'weights': tensor([0.7982]), 'bias': tensor([0.2586])})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "# An epoch is one loop over the entire dataset\n",
    "epochs = 100\n",
    "\n",
    "### Training \n",
    "# 0. loop through the data\n",
    "for epoch in range(epochs):\n",
    "    # set the model to training mode\n",
    "    model_0.train()   # Set the parameters to that require gradients\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train)     # input first, target next\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    # 3. optimize zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. perform backwardpropagation on the loss with respect to the model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. step the optimizer (perform gradient descent)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    model_0.eval()    # turn off gradient tracking or equivalently\n",
    "    with torch.inference_mode():\n",
    "        \n",
    "\n",
    "    ## print out model state_dict\n",
    "    print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "974203c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-0.3952])), ('bias', tensor([0.6719]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce3d5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## real parameters\n",
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2269ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how model predicts `y_test` based on `X_test`\n",
    "\n",
    "with torch.inference_mode():   # this disables gradient tracking, make pytorch use less memory\n",
    "    y_preds_new = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f0602b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_preds_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m plt.scatter(X_train, y_train, label=\u001b[33m\"\u001b[39m\u001b[33mTraining Values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m plt.scatter(X_test, y_test, label=\u001b[33m\"\u001b[39m\u001b[33mIdeal Values\u001b[39m\u001b[33m\"\u001b[39m, c = \u001b[33m'\u001b[39m\u001b[33mg\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m plt.scatter(X_test, \u001b[43my_preds_new\u001b[49m, label=\u001b[33m\"\u001b[39m\u001b[33mModel Predictions\u001b[39m\u001b[33m\"\u001b[39m, c = \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m plt.legend()\n\u001b[32m     10\u001b[39m plt.show()    \u001b[38;5;66;03m# poor model! \u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_preds_new' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## lets compare predictions with ideal values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.scatter(X_train, y_train, label=\"Training Values\")\n",
    "plt.scatter(X_test, y_test, label=\"Ideal Values\", c = 'g')\n",
    "plt.scatter(X_test, y_preds_new, label=\"Model Predictions\", c = 'r')\n",
    "plt.legend()\n",
    "plt.show()    # poor model! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcomputing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
