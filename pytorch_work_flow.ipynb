{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aa42bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f31234bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000],\n",
       "        [0.3140],\n",
       "        [0.3280],\n",
       "        [0.3420],\n",
       "        [0.3560],\n",
       "        [0.3700],\n",
       "        [0.3840],\n",
       "        [0.3980],\n",
       "        [0.4120],\n",
       "        [0.4260]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Data Preparation and Loading\n",
    "# create **known** parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# create \n",
    "start = 0\n",
    "end = 1\n",
    "steps = 0.02\n",
    "X = torch.arange(start, end, steps).unsqueeze(dim=1) # add 1 dims\n",
    "\n",
    "y = weight * X + bias\n",
    "X[:10]\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc674f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Spliting data into training and test sets    \n",
    "# traing, validation and test set\n",
    "\n",
    "# creating training set\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94397e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a# Visualize, Visualize, Visualize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf38444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14})\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28b5dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f889bcf",
   "metadata": {},
   "source": [
    "#### Build a model\n",
    "Create linear regression model class\n",
    " building classes that can use the following link:\n",
    "https://realpython.com/python-classes/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "663a2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what model does:\n",
    "# start with random weights and bias\n",
    "# look at the training data and adjust weights and bias to better represent the data\n",
    "\n",
    "# through two main algorithms:\n",
    "# 1. Gradient Descent\n",
    "# 2. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65540223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # initialize model parameters (weights and bias)\n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                                requires_grad = True,\n",
    "                                                dtype = torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad = True,\n",
    "                                             dtype = torch.float))\n",
    "        # Forward method to define the computation in the model\n",
    "    def forward(self,x: torch.Tensor) -> torch.Tensor: # x is input data\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af8be721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through two main algorithms\n",
    "# 1. Gradient descent\n",
    "# 2. Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9222c0c",
   "metadata": {},
   "source": [
    "### Pytorch model biulding essential \n",
    "\n",
    "__torch.nn__ - contains all of the buildings for computational graphs\n",
    "\n",
    "__torch.nn.Parameter__ - what parameters should our model try and learn\n",
    "\n",
    "__torch.nn.Module__ - The base class for all neural network modules\n",
    "\n",
    "__torch.optim__ - this where the optimizers in PyTorch live, help with gradient descent\n",
    "\n",
    "__def forward()__ - All nn.Module subclasses require you to overwrite forward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0d6e2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "## access to the model parameters\n",
    "model_0.parameters()\n",
    "\n",
    "torch.manual_seed(42)   # reproducibility of the model parameters\n",
    "\n",
    "list(model_0.parameters())\n",
    "\n",
    "## the better way to access model parameters\n",
    "model_0.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60261897",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ideal parameters are predefined earlier\n",
    "# weight = 0.7\n",
    "# bias = 0.3\n",
    "\n",
    "# the model task is to start from random parameters and learn the ideal parameters\n",
    "# making prediction using `torch.inference_mode()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7887106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8000],\n",
       "         [0.8200],\n",
       "         [0.8400],\n",
       "         [0.8600],\n",
       "         [0.8800],\n",
       "         [0.9000],\n",
       "         [0.9200],\n",
       "         [0.9400],\n",
       "         [0.9600],\n",
       "         [0.9800]]),\n",
       " tensor([[0.8600],\n",
       "         [0.8740],\n",
       "         [0.8880],\n",
       "         [0.9020],\n",
       "         [0.9160],\n",
       "         [0.9300],\n",
       "         [0.9440],\n",
       "         [0.9580],\n",
       "         [0.9720],\n",
       "         [0.9860]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a855f805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how model predicts `y_test` based on `X_test`\n",
    "with torch.inference_mode():   # this disables gradient tracking, make pytorch use less memory\n",
    "    y_preds = model_0(X_test)\n",
    "y_preds\n",
    "\n",
    "## alternatively one can use\n",
    "# with torch.no_grad():\n",
    "#     y_preds = model_0(X_test)\n",
    "# y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e57c586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8       ],\n",
       "        [0.82      ],\n",
       "        [0.84000003],\n",
       "        [0.86      ],\n",
       "        [0.88      ],\n",
       "        [0.90000004],\n",
       "        [0.92      ],\n",
       "        [0.94      ],\n",
       "        [0.96      ],\n",
       "        [0.98      ]], dtype=float32),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train.numpy()), type(y_train.numpy()), type(X_test.numpy()), type(y_test.numpy())\n",
    "X_test.numpy(), y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b451ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## lets compare predictions with ideal values\n",
    "import numpy as np\n",
    "X = (X_train.numpy())\n",
    "y = (y_train.numpy())\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.scatter(X, y, label=\"Training Values\")\n",
    "# plt.scatter(X_test, y_test, label=\"Ideal Values\", c = 'g')\n",
    "# plt.scatter(X_test, y_preds, label=\"Model Predictions\", c = 'r')\n",
    "plt.legend()\n",
    "plt.show()    # poor model! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe4f54",
   "metadata": {},
   "source": [
    "### Train model\n",
    "training model to move from some __unknown__ parms to some __known__ parms. \n",
    "\n",
    "one way: use __loss function__ \n",
    "\n",
    "* **Loss Function** A func to measure how wrong your models pred to ideal outputs, lower is better\n",
    "\n",
    "* __Optimizer__: takes into account the loss and adjust model's parms to improve the loss func, where we need\n",
    "    * A training loop\n",
    "    * A testing loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624bbf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "349aa843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4267d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## kind of loss functions\n",
    "## 1. Mean Absolute Error Loss --> `torch.nn.L1Loss()`          -- l_n = |y - ŷ|\n",
    "## 2. Mean Squared Error Loss --> `torch.nn.MSELoss()`          -- l_n = (y - ŷ)²\n",
    "## 3. Cross Entropy Loss --> `torch.nn.CrossEntropyLoss()`      -- l_n = -Σ(y * log(ŷ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66bfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924e7e5c",
   "metadata": {},
   "source": [
    "## Building a training loop in PyTorch\n",
    "\n",
    "0. loop through the data\n",
    "1. Forward pass  to make preds on data\n",
    "2. Calculate the loss\n",
    "3. Optomizer zero grad\n",
    "4. Loss Backward \n",
    "5. Optimizer step (__gradiant descent__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "553f987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use MAE loss\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "## setup an optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD(params = model_0.parameters(), lr=0.01)   # lr = learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b20364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Loss: 0.31288138031959534 | Test loss: 0.48106518387794495\n",
      "OrderedDict({'weights': tensor([0.3406]), 'bias': tensor([0.1388])})\n",
      "Epoch:10 | Loss: 0.1976713240146637 | Test loss: 0.3463551998138428\n",
      "OrderedDict({'weights': tensor([0.3796]), 'bias': tensor([0.2388])})\n",
      "Epoch:20 | Loss: 0.08908725529909134 | Test loss: 0.21729660034179688\n",
      "OrderedDict({'weights': tensor([0.4184]), 'bias': tensor([0.3333])})\n",
      "Epoch:30 | Loss: 0.053148526698350906 | Test loss: 0.14464017748832703\n",
      "OrderedDict({'weights': tensor([0.4512]), 'bias': tensor([0.3768])})\n",
      "Epoch:40 | Loss: 0.04543796554207802 | Test loss: 0.11360953003168106\n",
      "OrderedDict({'weights': tensor([0.4748]), 'bias': tensor([0.3868])})\n",
      "Epoch:50 | Loss: 0.04167863354086876 | Test loss: 0.09919948130846024\n",
      "OrderedDict({'weights': tensor([0.4938]), 'bias': tensor([0.3843])})\n",
      "Epoch:60 | Loss: 0.03818932920694351 | Test loss: 0.08886633068323135\n",
      "OrderedDict({'weights': tensor([0.5116]), 'bias': tensor([0.3788])})\n",
      "Epoch:70 | Loss: 0.03476089984178543 | Test loss: 0.0805937647819519\n",
      "OrderedDict({'weights': tensor([0.5288]), 'bias': tensor([0.3718])})\n",
      "Epoch:80 | Loss: 0.03132382780313492 | Test loss: 0.07232122868299484\n",
      "OrderedDict({'weights': tensor([0.5459]), 'bias': tensor([0.3648])})\n",
      "Epoch:90 | Loss: 0.02788739837706089 | Test loss: 0.06473556160926819\n",
      "OrderedDict({'weights': tensor([0.5629]), 'bias': tensor([0.3573])})\n",
      "Epoch:100 | Loss: 0.024458957836031914 | Test loss: 0.05646304413676262\n",
      "OrderedDict({'weights': tensor([0.5800]), 'bias': tensor([0.3503])})\n",
      "Epoch:110 | Loss: 0.021020207554101944 | Test loss: 0.04819049686193466\n",
      "OrderedDict({'weights': tensor([0.5972]), 'bias': tensor([0.3433])})\n",
      "Epoch:120 | Loss: 0.01758546568453312 | Test loss: 0.04060482233762741\n",
      "OrderedDict({'weights': tensor([0.6141]), 'bias': tensor([0.3358])})\n",
      "Epoch:130 | Loss: 0.014155393466353416 | Test loss: 0.03233227878808975\n",
      "OrderedDict({'weights': tensor([0.6313]), 'bias': tensor([0.3288])})\n",
      "Epoch:140 | Loss: 0.010716589167714119 | Test loss: 0.024059748277068138\n",
      "OrderedDict({'weights': tensor([0.6485]), 'bias': tensor([0.3218])})\n",
      "Epoch:150 | Loss: 0.0072835334576666355 | Test loss: 0.016474086791276932\n",
      "OrderedDict({'weights': tensor([0.6654]), 'bias': tensor([0.3143])})\n",
      "Epoch:160 | Loss: 0.0038517764769494534 | Test loss: 0.008201557211577892\n",
      "OrderedDict({'weights': tensor([0.6826]), 'bias': tensor([0.3073])})\n",
      "Epoch:170 | Loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "OrderedDict({'weights': tensor([0.6951]), 'bias': tensor([0.2993])})\n",
      "Epoch:180 | Loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "OrderedDict({'weights': tensor([0.6951]), 'bias': tensor([0.2993])})\n",
      "Epoch:190 | Loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "OrderedDict({'weights': tensor([0.6951]), 'bias': tensor([0.2993])})\n",
      "Epoch:200 | Loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "OrderedDict({'weights': tensor([0.6951]), 'bias': tensor([0.2993])})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "# An epoch is one loop over the entire dataset\n",
    "epochs = 201\n",
    "#===============================\n",
    "### Track model values\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "# ==============================\n",
    "### Training \n",
    "# 0. loop through the data\n",
    "for epoch in range(epochs):\n",
    "    # set the model to training mode\n",
    "    model_0.train()   # Set the parameters to that require gradients\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train)     # input first, target next\n",
    "    # print(f'Loss: {loss.item()}')\n",
    "    # 3. optimize zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. perform backwardpropagation on the loss with respect to the model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. step the optimizer (perform gradient descent)\n",
    "    optimizer.step()\n",
    "\n",
    "    #### Testing code\n",
    "    model_0.eval()    # turn off gradient tracking or equivalently\n",
    "    with torch.inference_mode():  # turn of gradient tracking\n",
    "        # 1. do the forward pass\n",
    "        test_pred = model_0(X_test)\n",
    "        # 2. calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 ==0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "\n",
    "        print(f'Epoch:{epoch} | Loss: {loss} | Test loss: {test_loss}')\n",
    "\n",
    "    ## print out model state_dict\n",
    "        print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "974203c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce3d5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## real parameters\n",
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2269ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how model predicts `y_test` based on `X_test`\n",
    "\n",
    "with torch.inference_mode():   # this disables gradient tracking, make pytorch use less memory\n",
    "    y_preds_new = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets compare predictions with ideal values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.scatter(X_train, y_train, label=\"Training Values\")\n",
    "plt.scatter(X_test, y_test, label=\"Ideal Values\", c = 'g')\n",
    "plt.scatter(X_test, y_preds_new, label=\"Model Predictions\", c = 'r')\n",
    "plt.legend()\n",
    "plt.show()    # poor model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0adf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curves\n",
    "# epoch_count, loss_values, test_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "074a46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.array(torch.tensor(loss_values).numpy())\n",
    "# loss_values = loss_values.detach()\n",
    "with torch.inference_mode():\n",
    "    loss_array = torch.tensor(loss_values).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0c6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b4e80460d0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Plot the loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_count, loss_array, label='Train Loss')\n",
    "plt.plot(epoch_count, test_loss_values, label='Test Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4430603",
   "metadata": {},
   "source": [
    "#### Saving model in Pytorch\n",
    "Three main models for saving and Loading model\n",
    "\n",
    "1. `torch.save()` save in python's pickle format\n",
    "2. `torch.load()` allows load a saved Pytorch object\n",
    "3. `torch.Module.load_state_dict()` load a model's saved state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b82ec79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m MODEL_PATH = MODEL_PATH / MODEL_NAME\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 3. Save the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtorch\u001b[49m.save(model_0.state_dict(), MODEL_PATH)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#### Saving our Pytorch model\n",
    "from pathlib import Path\n",
    "# 1. Create models dict \n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# 2. create model save path\n",
    "MODEL_NAME = '01_pytorch_001.pth'\n",
    "MODEL_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model\n",
    "torch.save(model_0.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b13bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 7426-ACFF\n",
      "\n",
      " Directory of c:\\Users\\10\\Desktop\\SharifUniversity\\Under_Learning_construction\\pytorch\n",
      "\n",
      "\n",
      " Directory of c:\\Users\\10\\Desktop\\SharifUniversity\\Under_Learning_construction\\pytorch\\models\n",
      "\n",
      "11/05/2025  04:43 PM    <DIR>          .\n",
      "11/05/2025  04:43 PM    <DIR>          ..\n",
      "               0 File(s)              0 bytes\n",
      "               2 Dir(s)   6,283,075,584 bytes free\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File Not Found\n"
     ]
    }
   ],
   "source": [
    "ls -l models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3beaf16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcomputing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
