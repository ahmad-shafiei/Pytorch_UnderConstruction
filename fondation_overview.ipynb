{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37ebd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets put all together\n",
    "\n",
    "# import Pytorch and matplotlib\n",
    "\n",
    "import torch, matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c38626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create device-agnostic code\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc02af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Data \n",
    "# y = w*x + b\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(1)\n",
    "y = weight * X + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ee4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_split = int(0.8 *len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4c3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the data\n",
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14})\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb3bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdab6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModelV2(\n",
       "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "              ('linear_layer.bias', tensor([0.8300]))]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a Pytorch linear model\n",
    "# this model is basically the same but more common\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## use nn.Linear() for creating the model parms\n",
    "        self.linear_layer = nn.Linear(in_features=1,\n",
    "                                       out_features=1)\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "    \n",
    "# set the manual seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = LinearRegressionModelV2()\n",
    "model_1, model_1.state_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModelV2(\n",
       "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model current device\n",
    "next(model_1.parameters()).device\n",
    "\n",
    "model_1.to(device)   ## but only cpu is available for me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6104a8",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    " we need:\n",
    " * Loss function\n",
    " * Optimizer\n",
    " * Training loop\n",
    " * Testing loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f77649",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# setup our optimizer\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "596faec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 10, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 20, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 30, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 40, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 50, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 60, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 70, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 80, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 90, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 100, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 110, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 120, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 130, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 140, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 150, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 160, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 170, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 180, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 190, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n",
      "Epoch: 200, Train Loss: 0.05761389806866646, Test Loss: 0.11862673610448837\n"
     ]
    }
   ],
   "source": [
    "### Lets write a training loop\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 201\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "\n",
    "    # 1. forward pass \n",
    "    y_pred = model_1(X_train)\n",
    "\n",
    "    # 2. calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # perform backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # 4. optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing \n",
    "\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "    if epoch % 10 ==0:\n",
    "       \n",
    "       print(f'Epoch: {epoch}, Train Loss: {loss.item()}, Test Loss: {test_loss.item()}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1f91ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('linear_layer.weight', tensor([[0.5779]])),\n",
       "              ('linear_layer.bias', tensor([0.2900]))]),\n",
       " (0.7, 0.3))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.state_dict(), (weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making and evaluating predictions\n",
    "\n",
    "# turn the model into evaluation mode\n",
    "\n",
    "model_1.eval()\n",
    "\n",
    "# make preds on the test data\n",
    "\n",
    "with torch.inference_mode():\n",
    "    test_pred = model_1(X_test)\n",
    "    test_loss = loss_fn(test_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932aa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving and loading\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcomputing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
